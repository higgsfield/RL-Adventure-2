{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 16\n",
    "env_name = \"Pendulum-v0\"\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "        \n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        # self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        mu    = self.actor(x)\n",
    "        std   = self.log_std.exp().expand_as(mu)\n",
    "        dist  = Normal(mu, std)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GAE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Proximal Policy Optimization Algorithm</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1707.06347\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    batch_size = states.size(0)\n",
    "    ids = np.random.permutation(batch_size)\n",
    "    ids = np.split(ids[:batch_size // mini_batch_size * mini_batch_size], batch_size // mini_batch_size)\n",
    "    for i in range(len(ids)):\n",
    "        yield states[ids[i], :], actions[ids[i], :], log_probs[ids[i], :], returns[ids[i], :], advantage[ids[i], :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            dist, value = model(state)\n",
    "            entropy = dist.entropy().mean()\n",
    "            new_log_probs = dist.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "\n",
    "            actor_loss  = - torch.min(surr1, surr2).mean()\n",
    "            critic_loss = (return_ - value).pow(2).mean()\n",
    "\n",
    "            loss = 0.5 * critic_loss + actor_loss - 0.001 * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.shape[0]\n",
    "\n",
    "#Hyper params:\n",
    "hidden_size      = 32\n",
    "lr               = 1e-3\n",
    "num_steps        = 128\n",
    "mini_batch_size  = 256\n",
    "ppo_epochs       = 30\n",
    "threshold_reward = -200\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames = 15000\n",
    "frame_idx  = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "early_stop = False\n",
    "\n",
    "while frame_idx < max_frames and not early_stop:\n",
    "\n",
    "    log_probs = []\n",
    "    values    = []\n",
    "    states    = []\n",
    "    actions   = []\n",
    "    rewards   = []\n",
    "    masks     = []\n",
    "    entropy = 0\n",
    "    state = envs.reset()\n",
    "    for _ in range(num_steps):\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value = model(state)\n",
    "\n",
    "        action = dist.sample()\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy += dist.entropy().mean()\n",
    "        \n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 1000 == 0:\n",
    "            test_reward = np.mean([test_env() for _ in range(10)])\n",
    "            test_rewards.append(test_reward)\n",
    "            plot(frame_idx, test_rewards)\n",
    "            #if test_reward > threshold_reward: early_stop = True\n",
    "            \n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "\n",
    "    returns   = torch.cat(returns).detach()\n",
    "    log_probs = torch.cat(log_probs).detach()\n",
    "    values    = torch.cat(values).detach()\n",
    "    states    = torch.cat(states)\n",
    "    actions   = torch.cat(actions)\n",
    "    advantage = returns - values\n",
    "    \n",
    "    ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Saving trajectories for GAIL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 reward: -250.46517216007143\n",
      "episode: 1 reward: -134.87809577173434\n",
      "episode: 2 reward: -142.29417979766473\n",
      "episode: 3 reward: -129.90417149454436\n",
      "episode: 4 reward: -130.7472181053005\n",
      "episode: 5 reward: -282.21452282011126\n",
      "episode: 6 reward: -129.3522544790129\n",
      "episode: 7 reward: -380.299482985933\n",
      "episode: 8 reward: -131.29455380251343\n",
      "episode: 9 reward: -272.48403628232336\n",
      "episode: 10 reward: -128.19224263873429\n",
      "episode: 11 reward: -265.61449361117457\n",
      "episode: 12 reward: -131.37505481339258\n",
      "episode: 13 reward: -407.07605842196887\n",
      "episode: 14 reward: -242.0739221742145\n",
      "episode: 15 reward: -261.07724188752417\n",
      "episode: 16 reward: -258.56678660584396\n",
      "episode: 17 reward: -2.5465678380060135\n",
      "episode: 18 reward: -251.13079686766548\n",
      "episode: 19 reward: -134.15033956008187\n",
      "episode: 20 reward: -127.6764437726261\n",
      "episode: 21 reward: -261.5115083622304\n",
      "episode: 22 reward: -252.99906246654774\n",
      "episode: 23 reward: -259.2445719455549\n",
      "episode: 24 reward: -137.3133322671017\n",
      "episode: 25 reward: -125.83997351192664\n",
      "episode: 26 reward: -134.99137176150555\n",
      "episode: 27 reward: -273.66033412435064\n",
      "episode: 28 reward: -256.2450633411993\n",
      "episode: 29 reward: -133.50140670364192\n",
      "episode: 30 reward: -129.8481945409907\n",
      "episode: 31 reward: -132.73926996669232\n",
      "episode: 32 reward: -131.5701323438954\n",
      "episode: 33 reward: -128.44500108300824\n",
      "episode: 34 reward: -135.63192687045287\n",
      "episode: 35 reward: -132.0739474035179\n",
      "episode: 36 reward: -250.35703650563957\n",
      "episode: 37 reward: -130.27367007874997\n",
      "episode: 38 reward: -260.905316715334\n",
      "episode: 39 reward: -131.2386179642477\n",
      "episode: 40 reward: -0.24553244691369985\n",
      "episode: 41 reward: -135.11597857540755\n",
      "episode: 42 reward: -128.9201763584982\n",
      "episode: 43 reward: -476.1742119907182\n",
      "episode: 44 reward: -124.86286322052598\n",
      "episode: 45 reward: -134.65496032733526\n",
      "episode: 46 reward: -135.5915592657633\n",
      "episode: 47 reward: -120.71290132126585\n",
      "episode: 48 reward: -130.06255303215207\n",
      "episode: 49 reward: -437.81202074314706\n",
      "episode: 50 reward: -137.66515647153182\n",
      "episode: 51 reward: -268.6184274539193\n",
      "episode: 52 reward: -129.61047170947467\n",
      "episode: 53 reward: -133.67749931839143\n",
      "episode: 54 reward: -122.9547406930679\n",
      "episode: 55 reward: -132.92650428984314\n",
      "episode: 56 reward: -307.56804230533345\n",
      "episode: 57 reward: -380.52790696515547\n",
      "episode: 58 reward: -251.29453441283067\n",
      "episode: 59 reward: -260.1189053800342\n",
      "episode: 60 reward: -284.1395492218562\n",
      "episode: 61 reward: -132.5349296005734\n",
      "episode: 62 reward: -127.3390034212662\n",
      "episode: 63 reward: -126.01183535527382\n",
      "episode: 64 reward: -0.3870677017389971\n",
      "episode: 65 reward: -123.84985901614772\n",
      "episode: 66 reward: -385.21012636038483\n",
      "episode: 67 reward: -315.8716868576024\n",
      "episode: 68 reward: -258.13507351866053\n",
      "episode: 69 reward: -292.6524888469423\n",
      "episode: 70 reward: -129.8961872306573\n",
      "episode: 71 reward: -129.43124214911546\n",
      "episode: 72 reward: -132.3841253799802\n",
      "episode: 73 reward: -134.1744306711291\n",
      "episode: 74 reward: -134.66671749644615\n",
      "episode: 75 reward: -271.2995497666664\n",
      "episode: 76 reward: -263.4260833438965\n",
      "episode: 77 reward: -136.7822300516544\n",
      "episode: 78 reward: -129.94470876311408\n",
      "episode: 79 reward: -0.6698802361971099\n",
      "episode: 80 reward: -127.58676105392746\n",
      "episode: 81 reward: -410.5231122642802\n",
      "episode: 82 reward: -132.20159997683498\n",
      "episode: 83 reward: -2.275314427136819\n",
      "episode: 84 reward: -130.79195386391225\n",
      "episode: 85 reward: -129.2238087049419\n",
      "episode: 86 reward: -289.11585684434783\n",
      "episode: 87 reward: -249.73871038645441\n",
      "episode: 88 reward: -132.86994587055054\n",
      "episode: 89 reward: -134.96720635415647\n",
      "episode: 90 reward: -132.91896866937503\n",
      "episode: 91 reward: -129.23083847834891\n",
      "episode: 92 reward: -128.21794628500686\n",
      "episode: 93 reward: -392.9957119025036\n",
      "episode: 94 reward: -268.6217339250764\n",
      "episode: 95 reward: -134.22900256588775\n",
      "episode: 96 reward: -264.21288651264274\n",
      "episode: 97 reward: -268.75278426430856\n",
      "episode: 98 reward: -327.8397508014795\n",
      "episode: 99 reward: -132.0954196218711\n",
      "episode: 100 reward: -129.09586011919654\n",
      "episode: 101 reward: -270.8926131741653\n",
      "episode: 102 reward: -387.7019151494871\n",
      "episode: 103 reward: -133.07366704873965\n",
      "episode: 104 reward: -256.36376070858876\n",
      "episode: 105 reward: -278.3566344221635\n",
      "episode: 106 reward: -281.8531103401584\n",
      "episode: 107 reward: -0.4331485834509031\n",
      "episode: 108 reward: -377.5285650086694\n",
      "episode: 109 reward: -130.4626614652813\n",
      "episode: 110 reward: -130.23087603085267\n",
      "episode: 111 reward: -1.7882693490999713\n",
      "episode: 112 reward: -132.05764338222613\n",
      "episode: 113 reward: -135.33979750507487\n",
      "episode: 114 reward: -127.3163720126511\n",
      "episode: 115 reward: -135.1850577596003\n",
      "episode: 116 reward: -131.38266207477267\n",
      "episode: 117 reward: -132.20251191494182\n",
      "episode: 118 reward: -129.65371768796516\n",
      "episode: 119 reward: -122.92780552041641\n",
      "episode: 120 reward: -134.3247330327645\n",
      "episode: 121 reward: -247.42110978686995\n",
      "episode: 122 reward: -132.45551124079614\n",
      "episode: 123 reward: -380.3088838887517\n",
      "episode: 124 reward: -280.6478430327161\n",
      "episode: 125 reward: -256.8915001144897\n",
      "episode: 126 reward: -132.69357007151146\n",
      "episode: 127 reward: -137.56196005131088\n",
      "episode: 128 reward: -134.44787735621816\n",
      "episode: 129 reward: -459.446699134065\n",
      "episode: 130 reward: -131.6005460352546\n",
      "episode: 131 reward: -1.395498515897097\n",
      "episode: 132 reward: -265.2077210831329\n",
      "episode: 133 reward: -258.32205844573707\n",
      "episode: 134 reward: -132.04788559974435\n",
      "episode: 135 reward: -130.09458204752977\n",
      "episode: 136 reward: -130.38941844860244\n",
      "episode: 137 reward: -279.6267884272643\n",
      "episode: 138 reward: -260.48156763561894\n",
      "episode: 139 reward: -266.14727203993544\n",
      "episode: 140 reward: -1.021914952331104\n",
      "episode: 141 reward: -132.43861661215968\n",
      "episode: 142 reward: -0.5840518196839863\n",
      "episode: 143 reward: -0.11717166646095413\n",
      "episode: 144 reward: -270.10375445294414\n",
      "episode: 145 reward: -280.70121054435964\n",
      "episode: 146 reward: -134.8181161513273\n",
      "episode: 147 reward: -270.6238887613736\n",
      "episode: 148 reward: -129.5323843676793\n",
      "episode: 149 reward: -134.44584962787593\n",
      "episode: 150 reward: -325.7386141278492\n",
      "episode: 151 reward: -136.8672202107664\n",
      "episode: 152 reward: -132.3133156408738\n",
      "episode: 153 reward: -267.8703647556608\n",
      "episode: 154 reward: -129.4383031649202\n",
      "episode: 155 reward: -505.5741921251039\n",
      "episode: 156 reward: -132.23368536760813\n",
      "episode: 157 reward: -386.797636001058\n",
      "episode: 158 reward: -1.4926554060945516\n",
      "episode: 159 reward: -128.98800585974428\n",
      "episode: 160 reward: -268.91982734498214\n",
      "episode: 161 reward: -407.4296617271461\n",
      "episode: 162 reward: -287.42369209368\n",
      "episode: 163 reward: -132.74310725473097\n",
      "episode: 164 reward: -132.17553510142955\n",
      "episode: 165 reward: -133.4700272797346\n",
      "episode: 166 reward: -131.7781540235434\n",
      "episode: 167 reward: -382.1942278756257\n",
      "episode: 168 reward: -270.48333065520154\n",
      "episode: 169 reward: -131.72875853373702\n",
      "episode: 170 reward: -129.22283953533326\n",
      "episode: 171 reward: -245.11199692265208\n",
      "episode: 172 reward: -130.26284815182888\n",
      "episode: 173 reward: -134.3274754198084\n",
      "episode: 174 reward: -0.4962861573341507\n",
      "episode: 175 reward: -137.51149742818407\n",
      "episode: 176 reward: -126.97965828978323\n",
      "episode: 177 reward: -460.1601110191893\n",
      "episode: 178 reward: -132.2897236102363\n",
      "episode: 179 reward: -272.87112841809045\n",
      "episode: 180 reward: -134.62083235614728\n",
      "episode: 181 reward: -135.70224473561046\n",
      "episode: 182 reward: -375.9853368023563\n",
      "episode: 183 reward: -278.7522948253276\n",
      "episode: 184 reward: -136.7692564335865\n",
      "episode: 185 reward: -0.10634445282023695\n",
      "episode: 186 reward: -253.84229855743231\n",
      "episode: 187 reward: -132.71678854509477\n",
      "episode: 188 reward: -267.0622011101807\n",
      "episode: 189 reward: -130.72028276859922\n",
      "episode: 190 reward: -259.58160379156385\n",
      "episode: 191 reward: -122.24457123255357\n",
      "episode: 192 reward: -128.5497972083456\n",
      "episode: 193 reward: -130.3130334953976\n",
      "episode: 194 reward: -1.343833002902933\n",
      "episode: 195 reward: -258.23925443972513\n",
      "episode: 196 reward: -0.2537767201717748\n",
      "episode: 197 reward: -126.89761391785963\n",
      "episode: 198 reward: -135.99597837166075\n",
      "episode: 199 reward: -0.9443003142036607\n",
      "episode: 200 reward: -292.68351871567404\n",
      "episode: 201 reward: -135.37741165253468\n",
      "episode: 202 reward: -258.9165732315837\n",
      "episode: 203 reward: -0.9805275314218908\n",
      "episode: 204 reward: -131.84484196203584\n",
      "episode: 205 reward: -380.5925552282618\n",
      "episode: 206 reward: -131.47906862793423\n",
      "episode: 207 reward: -130.65704302098104\n",
      "episode: 208 reward: -131.2675435440663\n",
      "episode: 209 reward: -1.7000718241625636\n",
      "episode: 210 reward: -0.352565583973318\n",
      "episode: 211 reward: -0.32879248988856197\n",
      "episode: 212 reward: -260.0101782401968\n",
      "episode: 213 reward: -297.5803853143848\n",
      "episode: 214 reward: -397.78655665462463\n",
      "episode: 215 reward: -263.84423802063156\n",
      "episode: 216 reward: -133.58802497874714\n",
      "episode: 217 reward: -270.9004962387377\n",
      "episode: 218 reward: -1.954849708831635\n",
      "episode: 219 reward: -399.09413350555803\n",
      "episode: 220 reward: -270.27409113116266\n",
      "episode: 221 reward: -381.1720258525721\n",
      "episode: 222 reward: -133.6619829447777\n",
      "episode: 223 reward: -255.8173540821602\n",
      "episode: 224 reward: -272.6024830455714\n",
      "episode: 225 reward: -129.50713018146752\n",
      "episode: 226 reward: -433.368037313021\n",
      "episode: 227 reward: -134.63468350553933\n",
      "episode: 228 reward: -485.0043706096516\n",
      "episode: 229 reward: -132.00440040025276\n",
      "episode: 230 reward: -269.55518148770386\n",
      "episode: 231 reward: -131.44129409779495\n",
      "episode: 232 reward: -382.73420989369623\n",
      "episode: 233 reward: -277.7278842226695\n",
      "episode: 234 reward: -400.14093798697667\n",
      "episode: 235 reward: -241.81396161911792\n",
      "episode: 236 reward: -269.2840624375213\n",
      "episode: 237 reward: -2.4742013842195507\n",
      "episode: 238 reward: -135.30704400778424\n",
      "episode: 239 reward: -0.17672691345367655\n",
      "episode: 240 reward: -269.0637588117464\n",
      "episode: 241 reward: -1.8376804063318701\n",
      "episode: 242 reward: -249.60907758786246\n",
      "episode: 243 reward: -0.30327255215737514\n",
      "episode: 244 reward: -256.04771446971534\n",
      "episode: 245 reward: -130.46080573823863\n",
      "episode: 246 reward: -0.8301837150294652\n",
      "episode: 247 reward: -269.89119142173433\n",
      "episode: 248 reward: -271.0986105992463\n",
      "episode: 249 reward: -134.38816801247967\n",
      "\n",
      "(50000, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "\n",
    "max_expert_num = 50000\n",
    "num_steps = 0\n",
    "expert_traj = []\n",
    "\n",
    "for i_episode in count():\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        action = dist.sample().cpu().numpy()[0]\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        expert_traj.append(np.hstack([state, action]))\n",
    "        num_steps += 1\n",
    "    \n",
    "    print(\"episode:\", i_episode, \"reward:\", total_reward)\n",
    "    \n",
    "    if num_steps >= max_expert_num:\n",
    "        break\n",
    "        \n",
    "expert_traj = np.stack(expert_traj)\n",
    "print()\n",
    "print(expert_traj.shape)\n",
    "print()\n",
    "np.save(\"expert_traj.npy\", expert_traj)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}